{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "    <meta http-equiv=\"Content-Style-Type\" content=\"text/css\" />\n",
    "    <meta name=\"generator\" content=\"pandoc\" />\n",
    "    <title></title>\n",
    "    <style type=\"text/css\">code{white-space: pre;}</style>\n",
    "  </head>\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "<h1> AMI </h1> \n",
    "<h1> Aprendizaje Supervisado: Regresores </h1>\n",
    "\n",
    "<br>\n",
    "    \n",
    "En esta pr谩ctica implementaremos en Python sistemas regresores. Como se ha indicado este mecanismo es utilizado en el contexto del aprendizaje m谩quina para predecir el valor de variables de salida continuas y es de tipo supervisado ya que debemos contar con el valor de salida asociado a cada conjunto de entradas. \n",
    "\n",
    "En la pr贸xima pr谩ctica estudiaremos el caso de variables de salida discreta (sistemas clasificadores), y para ello\n",
    "nos valdremos de los conceptos estudiados durante esta primera pr谩ctica. \n",
    "\n",
    "Para la implementaci贸n de mecanismos de aprendizaje m谩quina es habitual enfrentarnos a alg煤n problema de optimizaci贸n. Por ejemplo, elegir los par谩metros de la hip贸tesis h<sub>胃</sub>(x) de tal modo que el coste sea el menos por posible. De los diversos mecanismos posibles de optimizaci贸n, nosotros implementaremos y usaremos el m茅todo de las ecuaciones normales y el descenso del gradiente en esta pr谩ctica.\n",
    "\n",
    "Al finalizar veremos asimismo como mediante las librer铆as de Python podemos resolver r谩pidamente problemas de este tipo. Internamente har谩 uso de soluciones similares a las que nosotros hemos desarrollado paso a paso. \n",
    "\n",
    "<h2> Regresores lineales univariantes </h2>\n",
    "\n",
    "Comenzaremos con el caso m谩s sencillo, un regresor con una s贸la variable independiente (<em>feature</em>) en terminolog铆a de aprendizaje m谩quina y una s贸la salida (<em>target</em>). Primero cargaremos algunas librer铆as y generaremos un dataset de prueba, y lo mostramos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Para generar figuras\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Establecemos la semilla para generar siempre los mismos resultados\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generamos dataset para pruebas\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Mostramos el dataset\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Aproximaci贸n lineal sin t茅rmino independiente </h3>\n",
    "\n",
    "La hip贸tesis lineal pura es de la forma:  h<sub>胃</sub>(x) = 胃x, siendo 胃 un escalar. Vamos a buscar el mejor valor para 胃 a la vista de los datos. Para ello queremos minimizar la funci贸n de coste J(胃) (el MSE) entre los valores reales y la aproximaci贸n. \n",
    "\n",
    "Es decir:\n",
    "\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$J(\\theta)$=MSE=$\\frac{1}{m} \\sum_{i=1}^m (y^{(i)} - h_{\\theta}(x^{(i)})^2$</span></font></p>\n",
    "\n",
    "Sustituyendo la funci贸n de hip贸tesis: \n",
    "\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$J(\\theta)$=$\\frac{1}{m} \\sum_{i=1}^m (y^{(i)} - \\theta x^{(i)})^2$</span></font></p>\n",
    "\n",
    "Esta expresi贸n la podemos \"compactar\" escribiendola con matrices y vectores:\n",
    "\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$J(\\theta)$=$\\frac{1}{m}\\;(Y-X\\theta)'(Y-X\\theta)$</span></font></p>\n",
    "\n",
    "<h4> Cuesti贸n: Proporcione la f贸rmula y complete el c贸digo Python para obtener el 胃 贸ptimo en una regresi贸n lineal sin t茅rmino independiente</h4>\n",
    "\n",
    "Es decir, debe obtener: <font size=\"+1\"><span class=\"math inline\">$\\min\\limits_{\\theta} J(\\theta)$</span></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soluci贸n:\n",
    "    \n",
    "En este caso deber铆amos derivar la expresi贸n anterior e igualarla a cero. Es decir: \n",
    "    \n",
    "\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$\\frac{d J(\\theta)}{d \\theta}=-\\frac{1}{m}(X'(Y-X\\theta) + ((Y-X\\theta)'X)') = -\\frac{1}{m}(X'Y - X'X\\theta + X'Y - X'X\\theta) = -\\frac{2}{m}(X'Y - X'X\\theta) = 0$</span></font></p>\n",
    "\n",
    "Despejando 胃 obtenemos:\n",
    "\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$\\theta=(X'X)^{-1}X'Y$</span></font></p>\n",
    "\n",
    "Nota 1: Aunque X no es invertible (X'X) si puede serlo al ser cuadrada. Esta ecuaci贸n de resoluci贸n se denomina <b>ecuaci贸n normal</b>\n",
    "\n",
    "Nota 2: Al trabajar con matrices observe que <font size=\"+1\"><span class=\"math inline\">$d(AB) = (dA) B + (A (dB))'$</span></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_best = # DEBE COMPLETAR \n",
    "theta_best\n",
    "X_new = np.array([[0], [2]])\n",
    "y_predict = # DEBE COMPLETAR\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Aproximaci贸n af铆n (lineal con t茅rmino independiente) </h3>\n",
    "\n",
    "<h4> Cuesti贸n: Repita el mismo proceso que antes, pero suponiendo que la hip贸tesis es una funci贸n lineal con un termino independiente </h4>\n",
    "\n",
    "<br>\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$h_{\\theta} (x) = \\theta_0 + \\theta_1 x$</span></font></p>\n",
    "\n",
    "Proporcione la f贸rmula y el c贸digo Python para obtener el vector <font size=\"+0.5\"><span class=\"math inline\">$\\theta =  \\begin{pmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1\n",
    "\\end{pmatrix}$</span></font> 贸ptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soluci贸n: \n",
    "\n",
    "DEBE COMPLETAR ESTE APARTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X]  # A帽adimos bias (x0 = 1) a cada instancia\n",
    "\n",
    "theta_best = # DEBE COMPLETAR \n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]  # A帽adimos bias (x0 = 1) a cada instancia\n",
    "y_predict = # DEBE COMPLETAR\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()\n",
    "\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Regresi贸n usando el m茅todo del descenso del gradiente</h3>\n",
    "\n",
    "En general no va a ser posible obtener directamente los par谩metros de 胃 贸ptimos, o hacerlo por el m茅todo de las ecuaciones normales puede ser muy lento. Vamos a ver por qu茅 en el siguiente ejercicio: \n",
    "\n",
    "<h4>Cuesti贸n: Obtenga el tiempo de ejecuci贸n necesario para calcular el 胃 贸ptimo para m=100, m=1000, m=10000 y m=100000 donde m es el n煤mero de instancias</h4>\n",
    "\n",
    "Nota 3: En ipython puede obtener el tiempo de ejecuci贸n de una instrucci贸n predeciendola de la funci贸n \"m谩gica\" %timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [100,1000,10000,100000]:\n",
    "    X_test = 2 * np.random.rand(m, 1)\n",
    "    y_test = 4 + 3 * X_test + np.random.randn(m, 1)\n",
    "    X_test_b = np.c_[np.ones((m, 1)), X_test]  # A帽adimos bias (x0 = 1) a cada instancia\n",
    "    print(m)\n",
    "    # DEBE COMPLETAR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El m茅todo del descenso del gradiente es una alternativa al c谩lculo explicito del 贸ptimo. Como hemos visto en teor铆a se basa en corregir sucesivamente el punto de trabajo, <font size=\"+1\"><span class=\"math inline\">$\\theta_i$</span></font>, moviendolo hacia la direcci贸n contrar铆a al m谩ximo crecimiento de la funci贸n de p茅rdida. Es decir, hac铆a <font size=\"+1\"><span class=\"math inline\">$-\\nabla J(\\theta_i)$</span></font>, de tal modo que se actualice el punto de trabajo a: \n",
    "\n",
    "<p><font size=\"+0.5\"><span class=\"math inline\">$\\theta_{i+1} = \\theta_i - \\alpha \\nabla J(\\theta_i)$</span></font></p>\n",
    "\n",
    "Donde <font size=\"+1\"><span class=\"math inline\">$\\alpha$</span></font> es el factor de aprendizaje (learning rate) y controla la velocidad de convergencia del algoritmo. Cuando mayor menos pasos habr谩 que dar hasta la convergencia, si bien, si es demasiado elevado puede hacer que el m茅todo no converja. \n",
    "\n",
    "<h4> Cuesti贸n: Complete el siguiente c贸digo con el c谩lculo del gradiente </h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "n_iterations = 1000\n",
    "theta = np.random.randn(2,1) # Punto inicial se escoge al azar\n",
    "\n",
    "def gradient(X_b,y,theta):\n",
    "#DEBE COMPLETAR\n",
    "             \n",
    "for iteration in range(n_iterations):\n",
    "    gradients = gradient(X_b,y,theta)\n",
    "    theta = theta - alpha * gradients\n",
    "\n",
    "y_predict_grad = # DEBE COMPLETAR\n",
    "print(y_predict_grad, y_predict) # Prediccion para los puntos x=0.0 y x=2.0,  comparamos con el anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n vamos a mostrar la influencia del learning rate, mostrando la soluci贸n obtenida iterativamente para diferentes valores de 伪:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_bgd = []\n",
    "\n",
    "def plot_gradient_descent(theta, alpha, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = # DEBE COMPLETAR\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new, y_predict, style)\n",
    "        theta = theta - alpha * gradient(X,y,theta)\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\alpha = {}$\".format(alpha), fontsize=16)\n",
    "    \n",
    "np.random.seed(11)    \n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "    \n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, alpha=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, alpha=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cuesti贸n: C谩lcule el tiempo de convergencia empleando los mismos n煤meros de instancias que en el caso anterior </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "n_iterations = 1000\n",
    "\n",
    "import timeit\n",
    "\n",
    "for m in [100,1000,10000,100000]:\n",
    "    X_test = 2 * np.random.rand(m, 1)\n",
    "    y_test = 4 + 3 * X_test + np.random.randn(m, 1)\n",
    "    X_test_b = np.c_[np.ones((m, 1)), X_test]  # A帽adimos bias (x0 = 1) a cada instancia\n",
    "    print(m)\n",
    "    start_time = timeit.default_timer()\n",
    "    # DEBE COMPLETAR\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Regresi贸n usando la librer铆a scikit-learn </h3>\n",
    "\n",
    "A continuaci贸n mostraremos el uso de las librer铆as scikit-learn de Python para poder abordar directamente problemas de regresi贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "y_predict_sklearn = lin_reg.predict(X_new) # Valor en x=0.0 y x=2.0, comparamos con el anterior\n",
    "print(y_predict, y_predict_grad, y_predict_sklearn) # Deber铆an coincidir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<h2> Regresores pol铆nomicos univariantes </h2>\n",
    "\n",
    "Para finalizar la sesi贸n de hoy estuadiaremos el caso de un regresor con una s贸la <em>feature</em>, donde la funci贸n de hip贸tesis va a ser de tipo pol铆nomico de grado P, es decir:\n",
    "\n",
    "<br>\n",
    "<p><font size=\"+1\"><span class=\"math inline\">$h_{\\theta} (x) = \\sum_{p=1}^P \\theta_p x^p$</span></font></p>\n",
    "\n",
    "Para estudiar este caso, crearemos un nuevo dataset donde una regresi贸n pol铆nomica sea m谩s adecuada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "np.random.seed(1)\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cuesti贸n: Obtenga la funci贸n de coste <span class=\"math inline\">$J(\\theta)$</span> y el gradiente <span class=\"math inline\">$\\nabla J(\\theta)$</span> para este caso. Represente el resultado para P desde 1 hasta 5.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBE COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Regresi贸n polin贸mica usando la librer铆a scikit-learn </h3>\n",
    "\n",
    "A continuaci贸n mostraremos el uso de las librer铆as scikit-learn de Python para poder abordar directamente la regresi贸n polin贸mica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False) # Configuramos el modelo\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "in_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_poly, y) # Entrenamos el modelo\n",
    "\n",
    "# Mostramos el resultado\n",
    "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "X_new_poly = poly_features.transform(X_new)\n",
    "y_new = lin_reg.predict(X_new_poly)\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Funci贸n hip贸tesis\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1> Funciones 煤tiles de Python para el desarrollo de la pr谩ctica </h1>\n",
    "\n",
    "<ul>\n",
    "<li> Multiplicacion matrices A y B con numpy: A.dot(B)\n",
    "<li> Traspuesta de matriz A con numpy: A.T\n",
    "<li> Inversi贸n de matriz A con numpy: np.linalg.inv(A)\n",
    "<li> Matriz A por vector  con numpy: A.dot(theta)\n",
    "<li> Medida de tiempo de una orden con ipython: %timeit ...\n",
    "<li> Medida de tiempo de un bloque con python: <br>\n",
    "    start_time = timeit.default_timer()<br>\n",
    "    ...<br>\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
